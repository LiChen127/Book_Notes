# 第五章 运输层

## 5.1 运输层协议概述

### 5.1.1 进程之间的通信

从通信和信息处理的角度来看，**运输层向它上面的应用层提供通信服务**, 它属于面向通信部分的最高层，同时也是用户功能的最底层。当网络的边缘部分中的两个主机使用网络的核心部分的功能进行端到端的通信时，只有主机的协议栈才有运输层，而网络核心部分中的路由器在转发分组时都只用到下三层的功能。

IP协议能够把源主机A发送出的分组按照首部中的目的地址送交到目的主机B，那么，为什么还需要运输层呢？

从IP层来说，通信的两端是两个主机。IP数据报的首部明确地标志了这两个主机的IP地址。
但“两个主机之间的通信”这种说法还不够清楚。这是因为，**真正进行通信的实体是在主机中的进程，是这个主机中的一个进程和另一个主机中的一个进程在交换数据**（即通信）​。

因此严格地讲，**两个主机进行通信就是两个主机中的应用进程互相通信。IP协议虽然能把分组送到目的主机，但是这个分组还停留在主机的网络层而没有交付主机中的应用进程**。

从运输层的角度来看，**通信的真正端点并不是主机而是主机的进程**。也就是说，**端到端的通信**是应用进程
之间的通信。

运输层有一个很重要的功能--复用(multiplexing)和分用(demultiplexing)。

这里的复用指的是发送方在不同的应用程序进程都可以使用同一个运输层协议发送数据，而分用指的是接收方的运输层在剥去报文的首部后能够把这些数据正确交付目的应用进程。

**运输层提供应用进程间的逻辑通信**

逻辑通信的意思是: 从应用层来看，只要把应用层报文交给下面的运输层，运输层就可以把这报文传送到对方的运输层，**好像这种通信就是沿水平方向直接传送数据。但事实上这两个运输层之间并没有一条水平方向的物理连接。数据的传送是沿着图中的虚线方向（经过多个层次）传送的**

逻辑通信的意思是好像是这样通信，但事实上并非真的这样通信

**网络层为主机之间提供逻辑通信，而运输层为应用进程之间提供端到端的逻辑通信**

运输层还要对收到的报文进行差错检测。(在网络层，IP数据报首部中的检验和字段，只检验首部是否出现差错而不检查数据部分。)

根据应用程序的不同需求, 运输层需要有两种不同的运输协议，即**面向连接的TCP**和**无连接的UDP**

**运输层向高层用户屏蔽了下面网络核心的细节, 它使得应用进程看见的好像就是两个运输层实体之间一条端到端的逻辑通信信道**

但是UDP和TCP有所区别, 当运输层采用面向连接的TCP协议时，尽管下面的网络是不可靠的(只提供尽最大努力服务，不确保正确)，但这种逻辑通信信道就相当于一条全双工的可靠信道。但当运输层采用无连接的UDP协议时，这种逻辑通信信道仍然是一条不可靠信道。

### 5.1.2 运输层的两个主要协议

TCP/IP运输层的两个主要协议都是因特网的正式标准，即:

1. 用户数据报协议UDP(User Datagram Protocol)
2. 传输控制协议TCP(Transimission Control protocol)

![alt text](image.png)

按照OSI的术语，两个对等的运输实体在通信时传送的数据单位叫做**运输协议数据单元TPDU(Trasport Protocol Data Unit)**

但是TCP/IP体系中，根据所使用的协议是TCP/UDP，分别称之为**TCP报文段或UDP用户数据报**

**UDP在传送数据之前不需要先建立连接。远地主机的运输层在收到UDP报文后，不需要给出任何确认。**

**TCP则提供面向连接的服务，在传送数据之前必须先建立连接，数据传送结束后要释放连接**

TCP不提供广播或多播服务。由于TCP要提供可靠的、面向连接的运输服务，因此不可避免地增加了许多的开销，如确认、流量控制、计时器以及连接管理等。这不仅使协议数据单元的首部增大很多，还要占用许多的处理机资源。

### 5.1.3 运输层的端口

应用层所有的应用进程都可以通过运输层再传送到IP层（网络层）​，**这就是复用**。

运输层从IP层收到数据后必须交付指明的应用进程，**这就是分用。**

在单个计算机中的进程是用进程标识符（一个不大的整数）来标志的。但是在因特网环境下，计算机操作系统所指派的这种进程标识符用来标志运行在应用层的各种应用进程则是不行的。这是因为在因特网上使用的计算机的操作系统种类很多，而不同的操作系统又使用不同格式的进程标识符。为了使运行不同操作系统的计算机的应用进程能够互相通信，就必须用统一的方法（而这种方法必须与特定操作系统无关）对TCP/IP体系的应用进程进行标志。

但是，把一个特定机器上运行的特定进程，指明为因特网上通信的最后的终点还是不可行的。这是因为进程的创建和撤销都是动态的，通信的一方几乎无法识别对方机器上的进程。另外，我们往往需要利用目的主机提供的功能来识别终点，而不需要知道具体实现这个功能的进程是哪一个

解决这个问题的方法就是在运输层使用**协议端口号(protocol port number)**也称之为**端口**

虽然通信的终点是应用进程，**但我们只要把要传送的报文交到目的主机的某一个合适的目的端口，剩下的工作（即最后交付目的进程）就由TCP来完成。**

注意: **这种在协议栈层的抽象的协议端口是软件端口，与路由器/交换机的硬件端口完全不同**

**硬件端口是不同硬件设备进行交互的接口，而软件端口是应用层的各种协议进程与运输实体进行层间交互的一种地址。**

不同的系统具体实现端口的方法不同

TCP/IP的运输层用一个16位端口号来标志一个端口。但请注意，端口号只具有本地意义，它只是为了标志本计算机应用层中的各个进程在和运输层交互时的层间接口。在因特网不同计算机中，相同的端口号是没有关联的。16位的端口号可允许有65 535个不同的端口号，这个数目对一个计算机来说是足够用的。

因特网上的计算机通信是采用客户-服务器方式。客户在发起通信请求时，必须先知道对方服务器的IP地址和端口号。因此运输层的端口号共分为下面的两大类:

1. 服务器端使用的端口号分为两类: 
   1. 熟知端口号(well-known port number)/系统端口号
   2. 登记端口号: 数值为1024～49151。这类端口号是为没有熟知端口号的应用程序使用的。
2. 客户端使用的端口号: 由于这类端口号仅在客户进程运行时才动态选择，因此又叫做短暂端口号[插图]。这类端口号是留给客户进程选择暂时使用。当服务器进程收到客户进程的报文时，就知道了客户进程所使用的端口号，因而可以把数据发送给客户进程。通信结束后，刚才已使用过的客户端口号就不复存在，这个端口号就可以供其他客户进程使用。

## 5.2 用户数据报协议UDP

### 5.2.1 UDP概述

用户数据报协议UDP只在IP的数据报服务之上增加了很少一点的功能，这就是复**用和分用的功能以及差错检测的功能**。

UDP的主要特点是:

1. UDP是无连接的: 发送数据之前不需要建立连接(发送数据结束也没有连接可释放), 减少了开销和发送数据之前的时延
2. UDP使用尽最大努力交付，即不保证可靠交付，主机不需要维持复杂的连接状态
3. UDP是面向报文的。发送方的UDP对应用程序交下来的报文，在添加首部后就向下交付IP层,UDP对应用层交下来的报文，既不合并，也不拆分，而是保留这些报文的边界。这就是说，应用层交给UDP多长的报文，UDP就照样发送，即一次发送一个报文。在接收方的UDP，对IP层交上来的UDP用户数据报，在去除首部后就原封不动地交付上层的应用进程。也就是说，UDP一次交付一个完整的报文。因此，应用程序必须选择合适大小的报文。若报文太长，UDP把它交给IP层后，IP层在传送时可能要进行分片，这会降低IP层的效率。反之，若报文太短，UDP把它交给IP层后，会使IP数据报的首部的相对长度太大，这也降低了IP层的效率。
4. UDP没有拥塞控制: 因此网络出现的拥塞不会使源主机的发送速率降低。这对某些实时应用是很重要的。很多的实时应用（如IP电话、实时视频会议等）要求源主机以恒定的速率发送数据，并且允许在网络发生拥塞时丢失一些数据，但却不允许数据有太大的时延。UDP正好适合这种要求。
5. UDP支持一对一、一对多、多对一和多对对的交互通信
6. UDP的首部开销小，只有8个字节，比TCP的20个字节首部要短

### 5.2.2 UDP的首部格式

用户数据报UDP只有两个字段:

1. 数据字段
2. 首字段

## 5.3 传输控制协议TCP概述

### 5.3.1 TCP最主要的特点

1. TCP是面向连接的运输层协议。也就是说，应用程序在使用TCP协议之前，必须先建立TCP连接。传输数据完毕之后，必须释放已建立的TCP连接。
2. 每条TCP连接只能由两个端点(endpoint),每条TCP连接只能是点对点的
3. TCP连接提供可靠交付的服务。通过TCP连接传送的数据、无差错、不丢失、不重复、并且按序到达
4. TCP提供全双工通信。TCP允许通信双方的应用进程在任何时候都能发送数据。TCP连接的两端都设有发送缓存和接收缓存，用来临时存放双向通信的数据。在发送时，应用程序在把数据传送给TCP的缓存后，就可以做自己的事，而TCP在合适的时候把数据发送出去。在接收时，TCP把收到的数据放入缓存，上层的应用进程在合适的时候读取缓存中的数据。
5. 面向字节流。TCP中的流指的是流入到进程或从进程中流出的字节序列。面向字节流”的含义是：虽然应用程序和TCP的交互是一次一个数据块（大小不等）​，但TCP把应用程序交下来的数据看成仅仅是一连串的无结构的字节流。TCP并不知道所传送的字节流的含义。TCP不保证接收方应用程序所收到的数据块和发送方应用程序所发出的数据块具有对应大小的关系（例如，发送方应用程序交给发送方的TCP共10个数据块，但接收方的TCP可能只用了4个数据块就把收到的字节流交付上层的应用程序）​。但接收方应用程序收到的字节流必须和发送方应用程序发出的字节流完全一样。当然，接收方的应用程序必须有能力识别收到的字节流，把它还原成有意义的应用层数据。

另外很重要的一点，TCP连接是一条虚连接(逻辑连接)

TCP报文段先要传送到IP层，加上IP首部后，再传送到数据链路层。再加上数据链路层的首部和尾部后，才离开主机发送到物理链路。

TCP和UDP在发送报文时所采用的样式完全不同。TCP并不关心应用进程一次把多长的报文发送到TCP的缓存中，而是根据对方给出的窗口值和当前网络拥塞的程度来决定一个报文段应该包含多少个字节(UDP发送的报文长度是应用进程给出的)

如果应用进程传送到TCP缓存的数据块太长，TCP就可以把它划分短一些再传送。如果应用进程一次只发来一个字节，TCP也可以等待积累有足够多的字节后再构成报文段发送出去。

### 5.3.2 TCP的连接

**TCP把连接作为最基本的抽象。**

每一条TCP连接有两个端点。那么TCP连接的端点是什么？不是主机，不是IP地址，不是应用进程，也不是协议端口
而是**套接字(socket)或接口**

**端口号拼接到(contatenated with) IP地址即构成了套接字。**

因此，**套接字的表示方法是在点分十进制的IP地址后面写上端口号，中间用冒号或逗号隔开**。

例如，若IP地址是192.3.4.5而端口号是80，那么得到的套接字就是(192.3.4.5:80)。

套接字socket = (IP地址: 端口号)

**每一条TCP连接唯一地被通信两端的两个端点(即两个套接字)所确定**

![alt text](image-1.png)

## 5.4 可靠传输的工作原理

TCP发送的报文段是交给IP层传送的。但IP层只能提供尽最大努力服务，也就是说，TCP下面的网络所提供的是不可靠的传输。因此，TCP必须采用适当的措施才能使得两个运输层之间的通信变得可靠。

理想的传输条件

1. 传输信道不差错
2. 不管发送方以多快的速度发送数据，接收方总是来得及处理收到的数据

### 5.4.1 停止等待协议

停止等待就是发送完一个分组(数据单元)后就停止发送，等待对方的确认。在收到确认之后再发送给下一个分组

1. 无差错情况
2. 出现差错: A只要超过了一段时间仍然没有收到确认，就认为刚才发送的分组丢失了，因而重传前面发送过的分组。这就叫做超时重传。要实现超时重传，就要在每发送完一个分组设置一个超时计时器。

注意:

  1. A发送完一个分组后，必须暂时保留已发送的分组的副本(超时重传时使用)。只有收到相应的确认后才能清除暂时保留的分组副本。
  2. 分组和确认分组都必须进行编号。这样才能明确是哪一个发送出去的分组收到了确认。而哪一个分组还没收到确认
  3. 超时计时器设置的重传时间应当比数据在分组传输的平均往返时间更长一些。

3. 确认丢失和确认迟到
4. 信道利用率: 缺点就是利用率太低，为了提高传输效率，发送方可以不使用低效率的停止等待协议，而是采用流水线传输。流水线传输就是发送方可连续发送多个分组，不必每发完一个分组就停顿下来等待对方的确认。这样可使信道上一直有数据不间断地在传送。显然，这种传输方式可以获得很高的信道利用率。

### 5.4.2 连续ARQ协议

![alt text](image-2.png)

发送方维持的发送窗口，它的意义是：位于发送窗口内的5个分组都可连续发送出去，而不需要等待对方的确认。这样，信道利用率就提高了。

连续ARQ协议规定，发送方每收到一个确认，就把发送窗口向前滑动一个分组的位置。

接收方采用累积确认的方式。这就是说，接收方不必对收到的分组逐个发送确认，而是在收到几个分组后，对按序到达的最后一个分组发送确认，这就表示：到这个分组为止的所有分组都已正确收到了。

累积确认有优点也有缺点。优点是：容易实现，即使确认丢失也不必重传。但缺点是不能向发送方反映出接收方已经正确收到的所有分组的信息。

## 5.5 TCP报文段的首部格式

TCP虽然是面向字节流的，但TCP传送的数据单元却是报文段。一个TCP报文段分为首部和数据两部分，而TCP的全部功能都体现在它首部中各字段的作用。因此，只有弄清TCP首部各字段的作用才能掌握TCP的工作原理。

TCP报文段首部的前20个字节是固定的，后面有4n字节是根据需要增加的选项(n为整数)。因此TCP首部的最小长度是20字节。

首部固定部分各字段的意义如下:

1. 源端口和目的端口: 各占两个字节，分别写入源端口号和目的端口号
2. 序号: 4个字节。序号范围是[0, 232 - 1]​，共232（即4 294 967 296）个序号。序号增加到232 - 1后，下一个序号就又回到0。也就是说，序号使用mod 232运算。TCP是面向字节流的。在一个TCP连接中传送的字节流中的每一个字节都按顺序编号。整个要传送的字节流的起始序号必须在连接建立时设置。首部中的序号字段值则指的是本报文段所发送的数据的第一个字节的序号。也称之为报文段序号
3. 确认号: 4个字节, 是期望收到对方下一个报文段的第一个数据字节的序号。
4. 数据偏移: 4个字节。它指出TCP报文段的数据起始处距离TCP报文段的起始处有多远。这个字段实际上是指出TCP报文段的首部长度。由于首部中还有长度不确定的选项字段，因此数据偏移字段是必要的。
5. 保留: 占6位，保留为今后使用，但目前应置为0。
6. 紧急URG(URGent): 当URG = 1时，表明紧急指针字段有效。它告诉系统此报文段中有紧急数据，应尽快传送(相当于高优先级的数据)，而不要按原来的排队顺序来传送。当URG置1时，发送应用进程就告诉发送方的TCP有紧急数据要传送。于是发送方TCP就把紧急数据插入到本报文段数据的最前面，而在紧急数据后面的数据仍是普通数据。这时要与首部中紧急指针(Urgent Pointer)字段配合使用。
7. 确认ACK(ACKnowlegment): 仅当ACK = 1时确认号字段才有效。当ACK = 0时，确认号无效。TCP规定，在连接建立后所有传送的报文段都必须把ACK置1。
8. 推送PSH(Push): 当两个应用进程进行交互式的通信时，有时在一端的应用进程希望在键入一个命令后立即就能够收到对方的响应。在这种情况下，TCP就可以使用推送(push)操作。这时，发送方TCP把PSH置1，并立即创建一个报文段发送出去。接收方TCP收到PSH = 1的报文段，就尽快地（即“推送”向前）交付接收应用进程，而不再等到整个缓存都填满了后再向上交付。
9. 复位RST(resst): 当RST = 1时，表明TCP连接中出现严重差错（如由于主机崩溃或其他原因）​，必须释放连接，然后再重新建立运输连接。RST置1还用来拒绝一个非法的报文段或拒绝打开一个连接。RST也可称为重建位或重置位。
10. 同步SYN(SYNchronization):  在连接建立时用来同步序号。当SYN = 1而ACK = 0时，表明这是一个连接请求报文段。对方若同意建立连接，则应在响应的报文段中使SYN = 1和ACK = 1。因此，SYN置为1就表示这是一个连接请求或连接接受报文
11. 终止FIN:  用来释放一个连接。当FIN = 1时，表明此报文段的发送方的数据已发送完毕，并要求释放运输连接。
12. 窗口: 占2字节。窗口值是[0, 216 - 1]之间的整数。窗口指的是发送本报文段的一方的接收窗口（而不是自己的发送窗口）​。窗口值告诉对方：从本报文段首部中的确认号算起，接收方目前允许对方发送的数据量。之所以要有这个限制，是因为接收方的数据缓存空间是有限的。总之，**窗口值作为接收方让发送方设置其发送窗口的依据**。(窗口字段明确指出了现在允许对方发送的数据量，窗口值经常在动态变化着)
13. 检验和: 占2字节。检验和字段检验的范围包括首部和数据这两部分。
14. 紧急指针: 占2字节。紧急指针仅在URG = 1时才有意义，它指出本报文段中的紧急数据的字节数（紧急数据结束后就是普通数据）​。因此，紧急指针指出了紧急数据的末尾在报文段中的位置。当所有紧急数据都处理完时，TCP就告诉应用程序恢复到正常操作。值得注意的是，即使窗口为零时也可发送紧急数据。
15. 选项: 长度可变，最长可达40字节。当没有使用“选项”时，TCP的首部长度是20字节。TCP最初只规定了一种选项，即最大报文段长度MSS (Maximum Segment Size) [RFC 879]​。请注意MSS这个名词的含义。MSS是每一个TCP报文段中的数据字段的最大长度。数据字段加上TCP首部才等于整个的TCP报文段。所以MSS并不是整个TCP报文段的最大长度，而是“TCP报文段长度减去TCP首部长度”​。

## 5.6 TCP可靠传输的实现

### 5.6.1 以字节为单位的滑动窗口

TCP的滑动窗口是以字节为单位的

### 5.6.2 超时重传时间的选择

TCP的发送方在规定的时间内没有收到确认就要重传已发送的报文段。这个很简单，但是重传时间的选择很复杂

TCP采用了一种自适应算法，它记录了一个报文段发出的时间，以及收到相应的确认的时间。
![alt text](image-3.png)
这两个时间之差就是**报文段的往返时间RTT**。TCP保留了RTT的一个**加权平均往返时间RTTs**
S代表Smoothed。进行的加权平均。

发送出一个报文段。设定的重传时间到了，还没有收到确认。于是重传报文段。经过了一段时间后，收到了确认报文段。现在的问题是：如何判定此确认报文段是对先发送的报文段的确认，还是对后来重传的报文段的确认？

由于重传的报文段和原来的报文段完全一样，因此源主机在收到确认后，就无法做出正确的判断，而正确的判断对确定加权平均RTTS的值关系很大。

Karn提出了一个算法：在计算加权平均RTTS时，只要报文段重传了，就不采用其往返时间样本。这样得出的加权平均RTTS和RTO就较准确。

但是，这又引起新的问题。设想出现这样的情况：报文段的时延突然增大了很多。因此在原来得出的重传时间内，不会收到确认报文段。于是就重传报文段。但根据Karn算法，不考虑重传的报文段的往返时间样本。这样，超时重传时间就无法更新。

方法是：报文段每重传一次，就把超时重传时间RTO增大一些。典型的做法是取新的重传时间为2倍的旧的重传时间。当不再发生报文段的重传时，才根据上面给出的(5-5)式计算超时重传时间。

### 5.6.3 选择确认SACK

若收到的报文段无差错，只是未按序号，中间还缺少一些序号的数据，那么能否设法只传送缺少的数据而不重传已经正确到达接收方的数据？

可以，选择确认就是可行的处理方法

RFC 2018规定，如果要使用选择确认SACK，那么在建立TCP连接时，就要在TCP首部的选项中加上“允许SACK”的选项，而双方必须都事先商定好。如果使用选择确认，那么原来首部中的“确认号字段”的用法仍然不变。只是以后在TCP报文段的首部中都增加了SACK选项，以便报告收到的不连续的字节块的边界。

然而，SACK文档并没有指明发送方应当怎样响应SACK。因此大多数的实现还是重传所有未被确认的数据块。

## 5.7 TCP的流量控制

### 5.7.1 利用滑动窗口实现流量控制

所谓的流量控制(flow control)就是让发送方的发送速率不要太快，要让接收方来得及接收

利用滑动窗口机制可以很方便地在TCP连接上实现对发送方的流量控制。

发送方的发送窗口不能超过接收方给出的接收窗口的数值。请注意，TCP的窗口单位是字节，不是报文段。

TCP为每一个连接设有一个持续计时器(persistence timer)。只要TCP连接的一方收到对方的零窗口通知，就启动持续计时器。若持续计时器设置的时间到期，就发送一个零窗口探测报文段（仅携带1字节的数据）​，而对方就在确认这个探测报文段时给出了现在的窗口值[插图]。如果窗口仍然是零，那么收到这个报文段的一方就重新设置持续计时器。如果窗口不是零，那么死锁的僵局就可以打破了。

### 5.7.2 必须考虑传输效率

前面讲过，应用进程把数据传送到TCP的发送缓存后，剩下的发送任务就由TCP来控制了。

有很多机制来控制TCP报文段的发送时机

1. TCP维持一个变量，等于最大报文段长度MSS,只要缓存中存放的数据达到MSS字节时，就组装成一个TCP报文段发送出去。
2. 由发送方的应用进程指明要求发送报文段，即TCP支持的push操作
3. 发送方的计时器期限到了，把当前已有的缓存数据装入报文段(长度不能超过MSS)

如何控制TCP发送报文段的时机仍然比较复杂

TCP的实现中广泛使用Nagle算法: 若发送应用进程要把发送的数据逐个字节送到TCP的发送缓存，则发送方就把第一个数据字节先发送出去，把后面到达的数据字节都缓存起来。当发送方收到对第一个数据字符的确认后，再把发送缓存中的所有数据封装成一个报文段发送出去，同时继续对随后到达的数据进行缓存。只有在收到对前一个报文段的确认后才继续发送下一个报文段。当数据到达较快而网络速率较慢时，用这样的方法可明显地减少所用的网络带宽。Nagle算法还规定，当到达的数据已达到发送窗口大小的一半或已达到报文段的最大长度时，就立即发送一个报文段。这样做，就可以有效地提高网络的吞吐量。

另一个问题叫做糊涂窗口综合征(silly window syndrome)

有时也会使TCP的性能变坏。设想一种情况：TCP接收方的缓存已满，而交互式的应用进程一次只从接收缓存中读取1个字节（这样就使接收缓存空间仅腾出1个字节）​，然后向发送方发送确认，并把窗口设置为1个字节（但发送的数据报是40字节长）​。接着，发送方又发来1个字节的数据（请注意，发送方发送的IP数据报是41字节长）​。接收方发回确认，仍然将窗口设置为1个字节。这样进行下去，使网络的效率很低。

要解决这个问题，可以让接收方等待一段时间，使得或者接收缓存已有足够空间容纳一个最长的报文段，或者等到接收缓存已有一半空闲的空间。只要出现这两种情况之一，接收方就发出确认报文，并向发送方通知当前的窗口大小。此外，发送方也不要发送太小的报文段，而是把数据积累成足够大的报文段，或达到接收方缓存的空间的一半大小。

## 5.8 TCP的拥塞控制

### 5.8.1 拥塞控制的一般原理

在计算机网络中的链路容量（即带宽）​、交换结点中的缓存和处理机等，都是网络的资源。在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏。这种情况就叫做拥塞(congestion)。

**对资源量的需求总和 > 可用资源**-> 拥塞条件

拥塞控制就是防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。拥塞控制所要做的都有一个前提，就是网络能够承受现有的网络负荷。拥塞控制是一个全局性的过程，涉及到所有的主机、所有的路由器，以及与降低网络传输性能有关的所有因素。但TCP连接的端点只要迟迟不能收到对方的确认信息，就猜想在当前网络中的某处很可能发生了拥塞，但这时却无法知道拥塞到底发生在网络的何处，也无法知道发生拥塞的具体原因（是访问某个服务器的通信量过大？还是在某个地区出现了自然灾害）​。

相反地，流量控制往往指的是点对点通信量地控制，是一个端到端的问题。流量控制所要作的就是抑制发送端发送数据的速率，以便使接收端来得及接收。

流量控制所要做的就是抑制发送端发送数据的速率，使得接收端来得及接收

![alt text](image-4.png)

随着提供的负载的增大，网络吞吐量的增长速率逐渐减小。也就是说，在网络吞吐量还未达到饱和时，就已经有一部分的输入分组被丢弃了。当网络的吞吐量明显地小于理想的吞吐量时，网络就进入了轻度拥塞的状态。更值得注意的是，当提供的负载达到某一数值时，网络的吞吐量反而随提供的负载的增大而下降，这时网络就进入了拥塞状态。当提供的负载继续增大到某一数值时，网络的吞吐量就下降到零，网络已无法工作。这就是所谓的死锁(deadlock)。

从大的角度来看，拥塞控制可以分为开环控制和闭环控制两种方法。

闭环控制基于反馈环路的概念。

属于闭环控制的措施:

1. 监测网络系统以便检测到拥塞在何时何处发生
2. 把拥塞发生的信息传送到可采取行动的地方
3. 调整网络系统的运行以解决出现的问题

### 5.8.2 几种拥塞控制方法

1999年公布的因特网建议标准RFC 2581定义了进行拥塞控制的四种算法:

1. 慢开始(slow-start)
2. 拥塞避免(congestion avoidance)
3. 快重传(fast retransmit)
4. 快恢复(fast recovery)

#### 慢开始

发送方维持一个叫做拥塞窗口 cwnd (congestion window)的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口等于拥塞窗口。

发送方控制拥塞窗口的原则是: 只要网络没有出现拥塞，拥塞窗口就再增大一些，以便把更多的分组发送出去。但只要网络出现拥塞，拥塞窗口就减小一些，以减少注入到网络中的分组数

发送方如何知道网络发生拥塞呢?

我们知道，当网络发生拥塞时，路由器就要丢弃分组。因此只要发送方没有按时收到应当到达的确认报文，就可以猜想网络可能出现了拥塞。现在通信线路的传输质量一般都很好，因传输出差错而丢弃分组的概率是很小的（远小于1 %）​。

拥塞窗口cwnd的大小如何变化

慢开始算法的思路: 当主机开始发送数据时，如果立即把大量数据字节注入网络，那么就有可能引起网络拥塞，因为现在并不清楚网络的负荷情况。经验证明，较好的方法是先探测一下，即由小到大逐渐增大发送窗口，也就是说，由小到大逐渐增大拥塞窗口数值。通常在刚刚开始发送报文段时，先把拥塞窗口cwnd设置为一个最大报文段MSS的数值。而在每收到一个对新的报文段的确认后，把拥塞窗口增加至多一个MSS的数值。用这样的方法逐步增大发送方的拥塞窗口cwnd，可以使分组注入到网络的速率更加合理。

使用慢开始算法后，每经过一个传输轮次(transimission round), 拥塞窗口cwnd就开始加倍

一个传输轮次所经历的时间其实就是往返时间RTT。不过使用“传输轮次”更加强调：把拥塞窗口cwnd所允许发送的报文段都连续发送出去，并收到了对已发送的最后一个字节的确认。

## 5.9 TCP的运输连接管理

TCP是面向连接的协议。运输连接是用来传送TCP报文的。TCP运输连接的建立和释放是每一次面向连接的通信中必不可少的过程。因此，运输连接就有三个阶段，即：**连接建立、数据传送和连接释放**

TCP要解决的问题:

1. 使得每一方确知对方的存在
2. 要允许双方协商一些参数
3. 能够对运输实体资源进程分配

TCP连接的建立采用客户服务器方式。

主动发起连接建立的应用进程叫做客户(client)，而被动等待连接建立的应用进程叫做服务器(server)

### 5.9.1 TCP的连接建立

A主动打开连接，B被动打开连接。

1. B的TCP服务器进程先创建传输控制块TCP(Transmission Conrtol Block)存储了每个连接中的一些重要信息, 准备接受客户进程的连接请求。然后服务器进程处理LISTEN(收听)状态，等待客户的连接请求。
2. A的TCP客户进程首先也创建传输控制块TCP, 然后向B发出连接请求报文段，这时候首部的同步位SYN=1，同时选择一个初始序号seq = x。TCP规定，SYN报文段(SYN = 1的报文段)不可以携带数据，但是要消耗掉一个序号。这时，TCP客户进程进入SYN-SENT(同步已发送)状态。
3. B收到连接请求报文段之后，如果同意建立连接，则向A发送确认。在确认报文段中应把SYN位和ACK位都置为1，确认号是ack = x + 1, 同时也为自己选择一个初始序号seq = y。请注意，这个报文段也不能携带数据，但同样要消耗掉一个序号。这时TCP服务器进程进入SYN-RCVD（同步收到）状态。
4. TCP客户进程收到B的确认后，还要向B给出确认。确认报文段的ACK位置置为1，确认号ack = y + 1，而自己的序号seq = x + 1。TCP的标准规定，ACK报文段可以携带数据。但如果不携带数据则不消耗序号，在这种情况下，下一个数据报文段的序号仍是seq = x +1。这时，TCP连接已经建立，A进入ESTABLISHED（已建立连接）状态。
5. B收到A的确认之后，也进去ESTABLISHED状态

上面给出的连接建立过程叫做**三次握手(three-way handshake)**

为什么A还要发送一次确认呢？这主要是为了防止已失效的连接请求报文段突然又传送到了B，因而产生错误。

### 5.9.2 TCP的连接释放

1. 数据传输结束后，通信的双方都可释放连接。现在A和B都处于ESTABLISHED状态。
2. A的应用进程先向其TCP发出连接释放报文段，并停止再发送数据，主动关闭TCP连接。A把连接释放报文段首部的终止控制位FIN置1，其序号seq = u，它等于前面已传送过的数据的最后一个字节的序号加1。这时A进入FIN-WAIT-1（终止等待1）状态，等待B的确认。请注意，TCP规定，FIN报文段即使不携带数据，它也消耗掉一个序号。
3. B收到连接释放报文段后立即发出确认，确认号ack = u + 1，而这个报文段自己的序号是v，等于B前面已传送过的数据的最后一个字节的序号+1。然后B就进入CLOSE-WAIT状态，TCP服务器进程这时候就应该通知高层应用进程，因而从A到B这个方向的连接就释放了，因而从A到B这个方向的连接就释放了，这时的TCP连接处于半关闭(half-close)状态，即A已经没有数据要发送了，但B若发送数据，A仍要接收。也就是说，从B到A这个方向的连接并未关闭，这个状态可能会持续一些时间。
4. A收到来自B的确认后，就进入FIN-WAIT-2（终止等待2）状态，等待B发出的连接释放报文段。
5. 若B已经没有要向A发送的数据，其应用进程就通知TCP释放连接。这时B发出的连接释放报文段必须使FIN = 1。现假定B的序号为w（在半关闭状态B可能又发送了一些数据）​。B还必须重复上次已发送过的确认号ack = u + 1。这时B就进入LAST-ACK（最后确认）状态，等待A的确认。
6. A在收到B的连接报文段之后，必须对此发出确认。在确认报文段中把ACK置为1，确认号ack = w + 1，而自己的序号是seq = u + 1（根据TCP标准，前面发送过的FIN报文段要消耗一个序号）​。然后进入到TIME-WAIT（时间等待）状态。请注意，现在TCP连接还没有释放掉。必须经过时间等待计时器(TIME-WAIT timer)设置的时间2MSL后，A才进入到CLOSED状态。
7. B只要收到了A发出的确认，就进入CLOSED状态。同样，B在撤销相应的传输控制块TCB后，就结束了这次的TCP连接。我们注意到，B结束TCP连接的时间要比A早一些。

TCP连接释放过程是四次挥手

#### 为什么A在TIME-WAIT状态必须等待2MSL的时间

### 5.9.3 TCP的有限状态机

